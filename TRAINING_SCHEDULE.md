# ğŸš€ SE-ST-Combined è®­ç»ƒè®¡åˆ’

## æ¨èè®­ç»ƒæ­¥æ•°ï¼š**40,000 - 50,000 steps**

### ç†ç”±ï¼š
1. âœ… SE encoder (600M) å·²å†»ç»“ â†’ åªè®­ç»ƒ ST éƒ¨åˆ† (48.9M params)
2. âœ… ST éƒ¨åˆ†å¤æ‚åº¦ä¸ STATE ç›¸å½“
3. âœ… è¾“å…¥æ˜¯ SE embeddingsï¼ˆå·²ç»è¿‡é¢„è®­ç»ƒï¼‰â†’ å¯èƒ½æ”¶æ•›æ›´å¿«
4. âš ï¸ ä½†æ–°çš„è¾“å…¥ç©ºé—´å¯èƒ½éœ€è¦é¢å¤–çš„é€‚åº”æ­¥æ•°

---

## å®Œæ•´è®­ç»ƒå‘½ä»¤ï¼ˆæ¨èï¼‰

```bash
se-st-train \
  ++data.kwargs.toml_config_path="data/starter.toml" \
  ++data.kwargs.perturbation_features_file="/data/ESM2_pert_features.pt" \
  ++data.kwargs.num_workers=8 \
  ++training.max_steps=40000 \
  ++training.ckpt_every_n_steps=5000 \
  ++training.batch_size=16 \
  ++training.lr=1e-4 \
  ++training.val_check_interval=500 \
  ++training.log_every_n_steps=50 \
  ++training.early_stopping=true \
  ++training.patience=10 \
  ++model.kwargs.input_dim=18080 \
  ++model.kwargs.hidden_dim=512 \
  ++model.kwargs.output_dim=18080 \
  ++model.kwargs.pert_dim=5120 \
  ++model.kwargs.se_model_path="SE-600M" \
  ++model.kwargs.se_checkpoint_path="SE-600M/se600m_epoch15.ckpt" \
  ++output_dir="competition" \
  ++name="se_st_combined_40k"
```

---

## å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `max_steps` | 40000 | æ€»è®­ç»ƒæ­¥æ•°ï¼ˆä¸ STATE å¯¹é½ï¼‰ |
| `ckpt_every_n_steps` | 5000 | æ¯ 5k æ­¥ä¿å­˜ä¸€æ¬¡ï¼ˆ8 ä¸ª checkpointsï¼‰ |
| `val_check_interval` | 500 | æ¯ 500 æ­¥éªŒè¯ä¸€æ¬¡ |
| `batch_size` | 16 | æ ¹æ® GPU å†…å­˜è°ƒæ•´ï¼ˆ8-32ï¼‰ |
| `lr` | 1e-4 | å­¦ä¹ ç‡ï¼ˆSTATE é»˜è®¤ï¼‰ |
| `early_stopping` | true | è‡ªåŠ¨åœæ­¢ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰ |
| `patience` | 10 | éªŒè¯ loss 10 æ¬¡ä¸ä¸‹é™åˆ™åœæ­¢ |
| `num_workers` | 8 | æ•°æ®åŠ è½½è¿›ç¨‹æ•° |

---

## è®­ç»ƒæ—¶é—´ä¼°ç®—

åŸºäºä½ çš„æµ‹è¯•è¿è¡Œï¼ˆ1000 stepsï¼‰ï¼š

- **1000 steps**: ~5 åˆ†é’Ÿ
- **5000 steps**: ~25 åˆ†é’Ÿ
- **20000 steps**: ~1.5 å°æ—¶
- **40000 steps**: ~3 å°æ—¶

**å®é™…æ—¶é—´å–å†³äº**ï¼š
- GPU å‹å·ï¼ˆA100 / V100 / T4ï¼‰
- Batch sizeï¼ˆ16 vs 32ï¼‰
- æ•°æ®åŠ è½½é€Ÿåº¦

---

## ç›‘æ§æŒ‡æ ‡

### ğŸŸ¢ è®­ç»ƒå¥åº·çš„ä¿¡å·ï¼š
```
Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 500/1000 [02:30<02:30, 3.3it/s, loss=2.5, val_loss=2.8]
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [05:00<00:00, 3.3it/s, loss=2.1, val_loss=2.3]
Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 500/1000 [02:30<02:30, 3.3it/s, loss=1.8, val_loss=2.0]
```

âœ… `loss` æŒç»­ä¸‹é™  
âœ… `val_loss` è·Ÿéšä¸‹é™  
âœ… `it/s` ç¨³å®šï¼ˆ3-5 iterations/secondï¼‰

---

### ğŸ”´ éœ€è¦è°ƒæ•´çš„ä¿¡å·ï¼š

**1. è¿‡æ‹Ÿåˆ**ï¼š
```
loss=1.2, val_loss=3.5  # val_loss >> loss
```
â†’ é™ä½æ¨¡å‹å¤æ‚åº¦æˆ–å¢åŠ æ­£åˆ™åŒ–

**2. æ¬ æ‹Ÿåˆ**ï¼š
```
loss=4.5, val_loss=4.6  # éƒ½å¾ˆé«˜
```
â†’ å¢åŠ æ¨¡å‹å®¹é‡æˆ–è®­ç»ƒæ›´å¤šæ­¥æ•°

**3. è®­ç»ƒä¸ç¨³å®š**ï¼š
```
loss=2.1 â†’ 5.3 â†’ 1.8 â†’ 4.2  # éœ‡è¡
```
â†’ é™ä½å­¦ä¹ ç‡ï¼ˆ1e-5ï¼‰æˆ–å¢åŠ  gradient clipping

**4. è®­ç»ƒå¤ªæ…¢**ï¼š
```
it/s < 1  # æ¯ç§’å°‘äº 1 iteration
```
â†’ å‡å°‘ `num_workers` æˆ–æ£€æŸ¥æ•°æ®åŠ è½½

---

## åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ˆå¯é€‰ï¼‰

å¦‚æœä¸ç¡®å®š 40k æ˜¯å¦è¶³å¤Ÿï¼Œå¯ä»¥åˆ†é˜¶æ®µï¼š

### Stage 1: Quick Test (5k steps)
```bash
se-st-train \
  ++training.max_steps=5000 \
  ++name="stage1_quick_test"
```

**ç›®æ ‡**: éªŒè¯æ¨¡å‹èƒ½æ”¶æ•›

---

### Stage 2: Medium Run (20k steps)
```bash
se-st-train \
  ++training.max_steps=20000 \
  ++model.checkpoint="competition/stage1_quick_test/checkpoint-step-5000.ckpt" \
  ++name="stage2_medium_run"
```

**ç›®æ ‡**: è§‚å¯Ÿ loss ä¸‹é™è¶‹åŠ¿

---

### Stage 3: Full Training (40k steps)
```bash
se-st-train \
  ++training.max_steps=40000 \
  ++model.checkpoint="competition/stage2_medium_run/checkpoint-step-20000.ckpt" \
  ++name="stage3_full_training"
```

**ç›®æ ‡**: å……åˆ†è®­ç»ƒåˆ°æ”¶æ•›

---

### Stage 4: Extended Training (å¦‚æœéœ€è¦)
```bash
se-st-train \
  ++training.max_steps=60000 \
  ++model.checkpoint="competition/stage3_full_training/checkpoint-step-40000.ckpt" \
  ++name="stage4_extended"
```

**æ¡ä»¶**: 40k æ­¥æ—¶ loss ä»åœ¨ä¸‹é™

---

## å¯¹æ¯”ï¼šä½ çš„æ¨¡å‹ vs STATE

| ç»´åº¦ | STATE | SE-ST-Combined |
|------|-------|----------------|
| **è¾“å…¥ç»´åº¦** | 18080 (genes) | 18080 (genes) |
| **ä¸­é—´è¡¨ç¤º** | ç›´æ¥ä½¿ç”¨ | SE embeddings (512D) |
| **Trainable Params** | ~50M | 48.9M |
| **å†»ç»“éƒ¨åˆ†** | æ—  | SE encoder (600M) |
| **è®­ç»ƒæ­¥æ•°** | 40,000 | **æ¨è 40,000-50,000** |

---

## FAQ

### Q1: ä¸ºä»€ä¹ˆä¸ç›´æ¥è®­ç»ƒ 100k æ­¥ï¼Ÿ
**A**: 
- ğŸ’° æ—¶é—´æˆæœ¬ï¼š100k æ­¥ ~7.5 å°æ—¶
- ğŸ“‰ æ”¶ç›Šé€’å‡ï¼š40k æ­¥å loss å¯èƒ½å·²ç»æ”¶æ•›
- âš ï¸ è¿‡æ‹Ÿåˆé£é™©ï¼šè®­ç»ƒå¤ªä¹…å¯èƒ½ä¼¤å®³æ³›åŒ–èƒ½åŠ›

### Q2: å¦‚æœ 40k æ­¥è¿˜æ²¡æ”¶æ•›æ€ä¹ˆåŠï¼Ÿ
**A**: 
```bash
# ä» checkpoint ç»§ç»­è®­ç»ƒ
se-st-train \
  ++training.max_steps=60000 \
  ++model.checkpoint="competition/se_st_combined_40k/checkpoint-step-40000.ckpt" \
  ++name="se_st_combined_60k"
```

### Q3: å¦‚ä½•çŸ¥é“æ¨¡å‹å·²ç»æ”¶æ•›ï¼Ÿ
**A**: è§‚å¯Ÿè¿™äº›ä¿¡å·ï¼š
1. âœ… Loss æ›²çº¿å¹³å°æœŸï¼ˆè¿ç»­ 5k æ­¥å˜åŒ– < 1%ï¼‰
2. âœ… Validation loss ä¸å†ä¸‹é™
3. âœ… Early stopping è§¦å‘

### Q4: æˆ‘çš„ GPU å†…å­˜ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ
**A**: è°ƒæ•´è¿™äº›å‚æ•°ï¼š
```bash
++training.batch_size=8        # é™ä½ batch size
++training.gradient_clip_val=1.0  # æ·»åŠ  gradient clipping
++training.accumulate_grad_batches=2  # æ¢¯åº¦ç´¯ç§¯
```

---

## æœ€ç»ˆå»ºè®®

**å¯¹äºä½ çš„ SE-ST-Combined æ¨¡å‹ï¼Œæˆ‘å»ºè®®ï¼š**

1. ğŸ¯ **é¦–æ¬¡å®Œæ•´è®­ç»ƒ**ï¼š40,000 steps
2. ğŸ“Š **ç›‘æ§æŒ‡æ ‡**ï¼šæ¯ 500 steps çœ‹ val_loss
3. â±ï¸ **é¢„è®¡æ—¶é—´**ï¼š~3 å°æ—¶ï¼ˆA100ï¼‰
4. ğŸ’¾ **ä¿å­˜ç­–ç•¥**ï¼šæ¯ 5k æ­¥ä¿å­˜ checkpoint
5. ğŸ›‘ **Early stopping**ï¼špatience=10ï¼ˆ5k stepsï¼‰

**å¦‚æœ 40k æ­¥æ—¶ï¼š**
- âœ… Loss å·²æ”¶æ•› â†’ å®Œæˆè®­ç»ƒ
- âš ï¸ ä»åœ¨ä¸‹é™ â†’ ç»§ç»­åˆ° 50k-60k
- âŒ è¿‡æ‹Ÿåˆ â†’ å›é€€åˆ°æ›´æ—©çš„ checkpoint

**å¼€å§‹è®­ç»ƒå§ï¼** ğŸš€

